{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Jobs Analyze\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group:\n",
    "* Anchal\n",
    "* Angela\n",
    "* Larissa\n",
    "* Fabio\n",
    "* Felipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This program extracts data from Indeed.ca website to analyze main caracteristics \n",
    "of Data Science Job opportunities in Toronto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### IMPORT LIBRARIES ####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import bs4\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re \n",
    "import requests\n",
    "import datetime\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### SEARCH ARGUMENTS ####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_job = \"Data Scientist\"\n",
    "input_quote = False # add quotation marks(\"\") to your input_job\n",
    "input_city = \"\" # leave empty if input_city is not specified\n",
    "input_state = \"Canada\"\n",
    "sign = \"+\"\n",
    "BASE_URL_indeed =  'https://ca.indeed.com/' #'http://www.indeed.com'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Function for Transform searching keywords #####\n",
    "def transform(input,sign, quote = False):\n",
    "    syntax = input.replace(\" \", sign)\n",
    "    if quote == True:\n",
    "        syntax = ''.join(['\"', syntax, '\"'])\n",
    "    return(syntax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# GENERATING BASE INDEED URL #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ca.indeed.com//jobs?q=Data+Scientist&l=Canada\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if not input_city: # if (input_city is \"\")\n",
    "    url_indeed_list = [ BASE_URL_indeed, '/jobs?q=', transform(input_job, sign, input_quote),\n",
    "                    '&l=', input_state]\n",
    "    url_indeed = ''.join(url_indeed_list)\n",
    "else: # input_city is not \"\"\n",
    "    url_indeed_list = [ BASE_URL_indeed, '/jobs?q=', transform(input_job, sign, input_quote),\n",
    "                    '&l=', transform(input_city, sign), '%2C+', input_state]\n",
    "    url_indeed = ''.join(url_indeed_list)\n",
    "\n",
    "print(url_indeed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the HTML code from the URL\n",
    "rawcode_indeed = requests.get(url_indeed)\n",
    "\n",
    "# Choose \"lxml\" as parser\n",
    "soup_indeed = BeautifulSoup(rawcode_indeed.text, \"lxml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total results:\n",
      "\n",
      "        Page 1 of 1,039 jobs\n",
      "1,039\n"
     ]
    }
   ],
   "source": [
    "# total number of results\n",
    "num_total_indeed = soup_indeed.find(\n",
    "                        id = 'searchCount').contents[0].split()[-2]\n",
    "\n",
    "print(\"total results:\")\n",
    "print(soup_indeed.find(id = 'searchCount').contents[0])\n",
    "print(soup_indeed.find(id = 'searchCount').contents[0].split()[-2])\n",
    "num_total_indeed = re.sub(\"[^0-9]\",\"\", num_total_indeed) # remove non-numeric characters in the string\n",
    "num_total_indeed = int(num_total_indeed)\n",
    "#print(num_total_indeed)\n",
    "\n",
    "# total number of pages\n",
    "num_pages_indeed = int(np.ceil(num_total_indeed/10.0))\n",
    "#print(num_pages_indeed)\n",
    "\n",
    "# create an empty dataframe\n",
    "df_base = pd.DataFrame()\n",
    "# the date for today\n",
    "now = datetime.datetime.now()\n",
    "now_str = now.strftime(\"%m/%d/%Y\")\n",
    "now_str_name=now.strftime('%m%d%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ function to clean text before scraping ########### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(dirty_text):\n",
    "\n",
    "    text = dirty_text\n",
    "\n",
    "    lines = (line.strip() for line in text.splitlines()) # break into lines\n",
    "\n",
    "    chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \")) # break multi-headlines into a line each\n",
    "    \n",
    "    text = ''.join(chunk for chunk in chunks if chunk).encode('utf-8') # Get rid of all blank lines and ends of line\n",
    "    \n",
    "    # Now clean out all of the unicode junk (this line works great!!!)\n",
    "    \n",
    "    try:\n",
    "        text = text.decode('unicode_escape').encode('ascii', 'ignore') # Need this as some websites aren't formatted\n",
    "    except:                                                            # in a way that this works, can occasionally throw\n",
    "        return                                                         # an exception\n",
    "   \n",
    "    #print(text)\n",
    "    text = text.decode('utf-8')\n",
    "    text = re.sub(\"[^a-zA-Z+3]\",\" \", text)  # Now get rid of any terms that aren't words (include 3 for d3.js)\n",
    "                                             # Also include + for C++\n",
    "    text = re.sub(r\"([a-z])([A-Z])\", r\"\\1 \\2\", text) # Fix spacing issue from merged words\n",
    "    \n",
    "    text = text.lower().split()  # Go to lower case and split them apart\n",
    "    \n",
    "    \n",
    "   # stop_words = set(stopwords.words(\"english\")) # Filter out any stop words\n",
    "   # text = [w for w in text if not w in stop_words]\n",
    "    \n",
    "    text = list(set(text)) # Last, just get the set of these. Ignore counts (we are just looking at whether a term existed\n",
    "                           # or not on the website)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######### CREATING DATA FRAME WITH ALL JOB OPPORTUNITIES URLS #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## functions ###########\n",
    "def Salary(soup):\n",
    "    try:\n",
    "        salary = soup.find( attrs = {'class' : 'jobsearch-JobMetadataHeader-item'})\n",
    "        return  salary.contents\n",
    "    except:\n",
    "        return 'Not Informed'\n",
    "    \n",
    "def Job_Type(soup):\n",
    "    try:\n",
    "        rawcode = requests.get(url)\n",
    "        soup = BeautifulSoup(rawcode.text, \"html.parser\")\n",
    "        job_type = soup.find( attrs = {'class' : 'jobsearch-JobMetadataHeader-item icl-u-xs-mt--xs'})\n",
    "        return  job_type.contents\n",
    "    except:\n",
    "        return 'Not Informed'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<a target=\"\" id=\"sja2\" data-tn-element=\"jobTitle\" \n",
    "#class=\"jobtitle turnstileLink visited\" href=\"https://ca.indeed.com/pagead/clk?mo=r&amp;ad=-6NYlbfkN0DfaJzxeKsHg3yNa09Lu8cQQduvjegwzxl5yjE4sdO8aCQ7r433WSCgz7HcYFllrIChqTJMS6QCmfssNe4X0QSHiOgrDwcCGBAYCZvI_BwQi7xLmaCBM0jiSrhcAf8rdymPFkMDSwpaPlZeI6fWymNruny32jwnnByw7jFGzo9NkW4X4yQ_PjrCR0hXfYjXumiRywYP9ZFPwJ05-BsjrYICoWayMmyV5luzrs47wlt6XiU39YnQnHLOmYEku1S_tF_og5cAF72x2FLAu4Jj5cF3wfBBNlfY9o4vvFCQ2zX8xZsaIZs8MZT600XjvA3vKNlcZ9fBxcQlN7V6ZXqyEyGaTPd1skBYqY1xerFEg8mS6V0Nds-l34VWELv7tXYxQ_-Xknjhui6qMm34NSRGlZLzJTzhh6WHe5XKDpRZgpQgxzLNcEewWW5x_4uDad7Z5RGOuHBqD3DBBrzOl4tFTt2aWNmlitCCXgGl0nQqh0zJc6aR5aiTUNMA3RAdxd1GCRaviSxDjc2I2qYiPSdz36Ts&amp;vjs=3&amp;p=2&amp;sk=&amp;fvj=0&amp;tk=1csfpbj6050so803&amp;jsa=240&amp;sal=0&amp;sal=0&amp;oc=1&amp;sal=0\" title=\"Data Scientist\" rel=\"noopener nofollow\" onmousedown=\"sjomd('sja2'); clk('sja2');\" \n",
    "#onclick=\"setRefineByCookie([]); sjoc('sja2',0); convCtr('SJ')\"><b>Data</b> <b>Scientist</b></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ca.indeed.com//jobs?q=Data+Scientist&l=Canada&start=10\n",
      "61c9aaeee416a1c6\n",
      "https://ca.indeed.com//viewjob?jk=61c9aaeee416a1c6\n",
      "Data Scientist\n",
      "Sun Life Financial\n",
      "4ca0cac253b0f9d2\n",
      "https://ca.indeed.com//viewjob?jk=4ca0cac253b0f9d2\n",
      "Data Scientist\n",
      "SPORTLOGiQ\n",
      "631aecbd912f8389\n",
      "https://ca.indeed.com//viewjob?jk=631aecbd912f8389\n",
      "Data Scientist, Algorithms & Data Systems\n",
      "Boxy Charm\n",
      "e5f3946130fe18b0\n",
      "https://ca.indeed.com//viewjob?jk=e5f3946130fe18b0\n",
      "Customer & Energy Data Scientist\n",
      "BC Hydro\n",
      "0271b3456b2ff5d9\n",
      "https://ca.indeed.com//viewjob?jk=0271b3456b2ff5d9\n",
      "Data Scientist\n",
      "ATB Financial\n",
      "Calgary, AB\n",
      "e22404d0acf974af\n",
      "https://ca.indeed.com//viewjob?jk=e22404d0acf974af\n",
      "Data Scientist\n",
      "Quartic.ai\n",
      "Oakville, ON\n",
      "3625131c23ab13f2\n",
      "https://ca.indeed.com//viewjob?jk=3625131c23ab13f2\n",
      "Data Scientist\n",
      "Xylem\n",
      "Mississauga, ON\n",
      "salary:Not Informed\n",
      "  *** Job 3625131c23ab13f2 has been appended in the Data Frame ***\n",
      "86e0e9a1dab7acf3\n",
      "https://ca.indeed.com//viewjob?jk=86e0e9a1dab7acf3\n",
      "Data Scientist\n",
      "Flipp\n",
      "Toronto, ON\n",
      "salary:Not Informed\n",
      "  *** Job 86e0e9a1dab7acf3 has been appended in the Data Frame ***\n",
      "53e47810168e80a1\n",
      "https://ca.indeed.com//viewjob?jk=53e47810168e80a1\n",
      "Senior Data Scientist - Analytics Research\n",
      "CIBC\n",
      "Toronto, ON\n",
      "salary:Not Informed\n",
      "  *** Job 53e47810168e80a1 has been appended in the Data Frame ***\n",
      "6e87ae66a10b3167\n",
      "https://ca.indeed.com//viewjob?jk=6e87ae66a10b3167\n",
      "Data Scientist\n",
      "Agility consulting Inc\n",
      "Toronto, ON\n",
      "salary:Not Informed\n",
      "  *** Job 6e87ae66a10b3167 has been appended in the Data Frame ***\n",
      "17972833a76841f6\n",
      "https://ca.indeed.com//viewjob?jk=17972833a76841f6\n",
      "Data Scientist (Deep Learning)\n",
      "SomaDetect\n",
      "St. Catharines, ON\n",
      "salary:Not Informed\n",
      "  *** Job 17972833a76841f6 has been appended in the Data Frame ***\n",
      "2a924ec145aa9cac\n",
      "https://ca.indeed.com//viewjob?jk=2a924ec145aa9cac\n",
      "Data Scientist Associate Director - Toronto, ON\n",
      "Scotiabank\n",
      "Toronto, ON\n",
      "salary:Not Informed\n",
      "  *** Job 2a924ec145aa9cac has been appended in the Data Frame ***\n",
      "96f5b2aafa9de20e\n",
      "https://ca.indeed.com//viewjob?jk=96f5b2aafa9de20e\n",
      "Data Scientist / Actuary\n",
      "Munich Re\n",
      "Toronto, ON\n",
      "salary:Not Informed\n",
      "  *** Job 96f5b2aafa9de20e has been appended in the Data Frame ***\n",
      "9062e869714ba1d8\n",
      "https://ca.indeed.com//viewjob?jk=9062e869714ba1d8\n",
      "Head of Data & Analytics\n",
      "WestJet\n",
      "Toronto, ON\n",
      "salary:Not Informed\n",
      "  *** Job 9062e869714ba1d8 has been appended in the Data Frame ***\n",
      "f929186fd05d4336\n",
      "https://ca.indeed.com//viewjob?jk=f929186fd05d4336\n",
      "Computer Scientist, Robotics and Deep Learning\n",
      "Pleiades Robotics\n",
      "643af532812b501e\n",
      "https://ca.indeed.com//viewjob?jk=643af532812b501e\n",
      "Data Scientist - Machine Learning\n",
      "Intact\n",
      "0bc5c4d7cc78fc39\n",
      "https://ca.indeed.com//viewjob?jk=0bc5c4d7cc78fc39\n",
      "Data Scientist\n",
      "Indeed Prime\n",
      "Finished...\n",
      "             City             CompanyName        Date    From  \\\n",
      "0     Mississauga                   Xylem  11/16/2018  Indeed   \n",
      "1         Toronto                   Flipp  11/16/2018  Indeed   \n",
      "2         Toronto                    CIBC  11/16/2018  Indeed   \n",
      "3         Toronto  Agility consulting Inc  11/16/2018  Indeed   \n",
      "4  St. Catharines              SomaDetect  11/16/2018  Indeed   \n",
      "\n",
      "                                             JobLink  \\\n",
      "0  https://ca.indeed.com//viewjob?jk=3625131c23ab...   \n",
      "1  https://ca.indeed.com//viewjob?jk=86e0e9a1dab7...   \n",
      "2  https://ca.indeed.com//viewjob?jk=53e47810168e...   \n",
      "3  https://ca.indeed.com//viewjob?jk=6e87ae66a10b...   \n",
      "4  https://ca.indeed.com//viewjob?jk=17972833a768...   \n",
      "\n",
      "                                     JobRequirements  \\\n",
      "0  \\n\\nData Scientist - Mississauga, ON - Indeed....   \n",
      "1  \\n\\nData Scientist - Toronto, ON - Indeed.com\\...   \n",
      "2  \\n\\nSenior Data Scientist - Analytics Research...   \n",
      "3  \\n\\nData Scientist - Toronto, ON - Indeed.com\\...   \n",
      "4  \\n\\nData Scientist (Deep Learning) - St. Catha...   \n",
      "\n",
      "                                     JobTitle       JobType            Job_ID  \\\n",
      "0                              Data Scientist  Not Informed  3625131c23ab13f2   \n",
      "1                              Data Scientist  Not Informed  86e0e9a1dab7acf3   \n",
      "2  Senior Data Scientist - Analytics Research  Not Informed  53e47810168e80a1   \n",
      "3                              Data Scientist  Not Informed  6e87ae66a10b3167   \n",
      "4              Data Scientist (Deep Learning)  Not Informed  17972833a76841f6   \n",
      "\n",
      "                                            Position Province        Salary  \n",
      "0  <h3 class=\"icl-u-xs-mb--xs icl-u-xs-mt--none j...       ON  Not Informed  \n",
      "1  <h3 class=\"icl-u-xs-mb--xs icl-u-xs-mt--none j...       ON  Not Informed  \n",
      "2  <h3 class=\"icl-u-xs-mb--xs icl-u-xs-mt--none j...       ON  Not Informed  \n",
      "3  <h3 class=\"icl-u-xs-mb--xs icl-u-xs-mt--none j...       ON  Not Informed  \n",
      "4  <h3 class=\"icl-u-xs-mb--xs icl-u-xs-mt--none j...       ON  Not Informed  \n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "##### Loop for all the total pages #####\n",
    "########################################\n",
    "\n",
    "num_pages_indeed = 1 \n",
    "df_base = pd.DataFrame()\n",
    "\n",
    "for i in range(1, num_pages_indeed+1):\n",
    "    # generate the URL\n",
    "    url = ''.join([url_indeed, '&start=', str(i*10)])\n",
    "    print(url)\n",
    "\n",
    "    # get  LXML\n",
    "    rawcode = requests.get(url)\n",
    "    soup_lxml = BeautifulSoup(rawcode.text, \"lxml\")\n",
    "    \n",
    "    \n",
    "    #Extracting the Salary\n",
    "\n",
    "\n",
    "    # pick out all the \"div\" with \"class=\"job-row\"\n",
    "    divs = soup_lxml.findAll(\"div\")\n",
    "    job_divs = [jp for jp in divs if not jp.get('class') is None\n",
    "                    and 'row' in jp.get('class')]\n",
    "\n",
    "    count = 1\n",
    "    for job in job_divs:\n",
    "        try:\n",
    "            # job id\n",
    "            id = job.get('data-jk', None)\n",
    "            print(id)\n",
    "            \n",
    "            # job link related to job id\n",
    "            link = BASE_URL_indeed + '/viewjob'+ '?jk=' + id\n",
    "            #link = 'https://ca.indeed.com/Data-Scientist-jobs-in-Canada?vjk=' + id\n",
    "            print(link)\n",
    "            \n",
    "            # job title\n",
    "            title = job.find('a', attrs={'data-tn-element': 'jobTitle'}).attrs['title']\n",
    "            print(title)\n",
    "            \n",
    "            #sja = 'sja'+ str(count)\n",
    "            #href = BASE_URL_indeed + job.find('a', attrs={'id': sja}).attrs['href']\n",
    "            \n",
    "            \n",
    "            #print(href)\n",
    "            #count = count + 1\n",
    "            # job company\n",
    "            company = job.find('span', {'class': 'company'}).text.strip()\n",
    "            print(company)\n",
    "            \n",
    "            # job location\n",
    "            location = job.find('span', {'class': 'location'}).text.strip()\n",
    "            print(location)\n",
    "            #city, province\n",
    "            city,province = location.split(',')\n",
    "            \n",
    "            ### html.parser - Felipe\n",
    "            r = requests.get(link)\n",
    "            soup_html = BeautifulSoup(r.text, \"html.parser\")\n",
    "            #print(soup_html)\n",
    "            \n",
    "            # salary\n",
    "            salary = Salary(soup_html)\n",
    "            print('salary:' + salary)\n",
    "            \n",
    "            # job type\n",
    "            jobtype = Job_Type(soup_html)\n",
    "\n",
    "            \n",
    "            #Extracting the Job Title\n",
    "            position = soup_html.find(attrs = {'class' : 'icl-u-xs-mb--xs icl-u-xs-mt--none jobsearch-JobInfoHeader-title'})\n",
    "            \n",
    "            \n",
    "           \n",
    "            # job Requirements\n",
    "            try:   \n",
    "                #page = requests.get(link)\n",
    "                #soup = BeautifulSoup(page.text, 'html.parser')\n",
    "                text  = soup_html.get_text()\n",
    "                jobrequirements = text\n",
    "                #jobrequirements = text_cleaner(text)\n",
    "                \n",
    "            except:\n",
    "                print('exception 1')\n",
    "                jobrequirements = 'Forbidden'\n",
    "\n",
    "            \n",
    "        except:\n",
    "            continue\n",
    "        print('  *** Job ' + id + ' has been appended in the Data Frame ***')\n",
    "        df_base = df_base.append(dict({'Job_ID': id,\n",
    "                                  'JobTitle': title,\n",
    "                                  'JobType':jobtype,\n",
    "                                  'CompanyName': company,\n",
    "                                  'Salary' : salary ,\n",
    "                                  'Position':position,\n",
    "                                  'City': city,\n",
    "                                  'Province':province,\n",
    "                                  'JobRequirements':jobrequirements,\n",
    "                                  'Date': now_str,\n",
    "                                  'From':\"Indeed\",\n",
    "                                  'JobLink':link}),ignore_index=True)\n",
    "        \n",
    "print('Finished...')\n",
    "print(df_base.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_base.to_csv('out.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# READING DATAFRAME AND SCRAPING JOB DESCRIPTION ############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_base.JobRequirements.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SkillID           Skill       Category\n",
      "0        1          Python           Hard\n",
      "1        2             SQL           Hard\n",
      "2        3         BigData           Hard\n",
      "3        4           NumPy           Hard\n",
      "4        5          Spring           Hard\n",
      "5        6      Mathematcs      Education\n",
      "6        7             SQL           Hard\n",
      "7        8      Statistics      Education\n",
      "8       -1  Not Identified  Not Idenified\n",
      "   kwID      KeyWord        JobTitle  Skill_ID\n",
      "0     1  mathematics  Data Scientist         6\n",
      "1     2         Math  Data Scientist         6\n",
      "2     3       python  Data Scientist         1\n",
      "3     4     big data  Data Scientist         3\n",
      "4     5      bigdata  Data Scientist         3\n",
      "5     6          sql  Java Developer         7\n",
      "6     7       spring  Java Developer         5\n",
      "7     8    Not match  Data Scientist        -1\n"
     ]
    }
   ],
   "source": [
    "skill_source = pd.read_excel('ds.xlsx', sheet_name='skill')\n",
    "\n",
    "\n",
    "kw = pd.read_excel('ds_kw.xlsx')\n",
    "\n",
    "print(skill_source)\n",
    "print(kw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Functions\n",
    "def find_skill(skill, jobReq ):\n",
    "    if skill in jobReq:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_skill_aux = pd.DataFrame(columns=['Job_ID', 'KeyWord', 'Skill_ID'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_ID</th>\n",
       "      <th>KeyWord</th>\n",
       "      <th>Skill_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Job_ID, KeyWord, Skill_ID]\n",
       "Index: []"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_skill_aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0     True\n",
      "1     True\n",
      "2     True\n",
      "3     True\n",
      "4     True\n",
      "5    False\n",
      "6    False\n",
      "7     True\n",
      "Name: JobTitle, dtype: bool, ['KeyWord', 'Skill_ID'])\n",
      "3625131c23ab13f2\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'KeyWord'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: an integer is required",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-138-06ad64ad96ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m#for idx, skills in k.iterrows():\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mskills\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mskill\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mskills\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"KeyWord\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskill\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mskill_ID\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mskills\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Skill_ID\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    764\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 766\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   3101\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3102\u001b[0m             return self._engine.get_value(s, k,\n\u001b[0;32m-> 3103\u001b[0;31m                                           tz=getattr(series.dtype, 'tz', None))\n\u001b[0m\u001b[1;32m   3104\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3105\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minferred_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'integer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'boolean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'KeyWord'"
     ]
    }
   ],
   "source": [
    "z = 0\n",
    "for index,row in df_base.iterrows():\n",
    "    k = kw.JobTitle == row[\"JobTitle\"], ['KeyWord', 'Skill_ID']\n",
    "    jobReq = row[\"JobRequirements\"]\n",
    "    print(k)\n",
    "    job_ID = row[\"Job_ID\"]\n",
    "    print(job_ID)\n",
    "    \n",
    "    #for idx, skills in k.iterrows():\n",
    "    for skills in k:\n",
    "        skill = skills[\"KeyWord\"]\n",
    "        print(skill)\n",
    "        skill_ID = skills[\"Skill_ID\"]\n",
    "        func = find_skill(skill, jobReq)\n",
    "        print(func)\n",
    "        if func:\n",
    "            print(job_ID, skill, skill_ID)\n",
    "            df_skill_aux.loc[z] = [job_ID, skill, skill_ID]\n",
    "            z += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_ID</th>\n",
       "      <th>KeyWord</th>\n",
       "      <th>Skill_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3625131c23ab13f2</td>\n",
       "      <td>mathematics</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3625131c23ab13f2</td>\n",
       "      <td>python</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79f244142735e51b</td>\n",
       "      <td>python</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9c977136e5f64e8a</td>\n",
       "      <td>python</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>85db0c4b9dd0d204</td>\n",
       "      <td>mathematics</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>d4a402329a3013c6</td>\n",
       "      <td>mathematics</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>e1de8b679753f22a</td>\n",
       "      <td>python</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bdf8400b27b22160</td>\n",
       "      <td>mathematics</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bdf8400b27b22160</td>\n",
       "      <td>python</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2172d8fe11ab66ae</td>\n",
       "      <td>python</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7fbc93979ed6cddb</td>\n",
       "      <td>python</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cadad937d6da507c</td>\n",
       "      <td>mathematics</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cadad937d6da507c</td>\n",
       "      <td>python</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>38152e90fde295f7</td>\n",
       "      <td>mathematics</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>38152e90fde295f7</td>\n",
       "      <td>python</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2146001e0333f895</td>\n",
       "      <td>mathematics</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Job_ID      KeyWord Skill_ID\n",
       "0   3625131c23ab13f2  mathematics        6\n",
       "1   3625131c23ab13f2       python        1\n",
       "2   79f244142735e51b       python        1\n",
       "3   9c977136e5f64e8a       python        1\n",
       "4   85db0c4b9dd0d204  mathematics        6\n",
       "5   d4a402329a3013c6  mathematics        6\n",
       "6   e1de8b679753f22a       python        1\n",
       "7   bdf8400b27b22160  mathematics        6\n",
       "8   bdf8400b27b22160       python        1\n",
       "9   2172d8fe11ab66ae       python        1\n",
       "10  7fbc93979ed6cddb       python        1\n",
       "11  cadad937d6da507c  mathematics        6\n",
       "12  cadad937d6da507c       python        1\n",
       "13  38152e90fde295f7  mathematics        6\n",
       "14  38152e90fde295f7       python        1\n",
       "15  2146001e0333f895  mathematics        6"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_skill_aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating df_tmp\n",
    "df_tmp = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_tmp = df_base.merge(df_skill_aux, how='left', left_on='Job_ID', right_on='ID')\n",
    "df_tmp = df_base.merge(df_skill_aux, how='left', left_on='Job_ID', right_on='Job_ID')\n",
    "df_tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############# Treating null values #################\n",
    "values = {'Skill_ID': '-1', 'KeyWord': \"Not found\"}\n",
    "df_tmp = df_tmp.fillna(value=values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_tmp['Skill_ID'] = df_tmp['Skill_ID'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SkillID</th>\n",
       "      <th>Skill</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Python</td>\n",
       "      <td>Hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>SQL</td>\n",
       "      <td>Hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>BigData</td>\n",
       "      <td>Hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>NumPy</td>\n",
       "      <td>Hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Spring</td>\n",
       "      <td>Hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Mathematcs</td>\n",
       "      <td>Education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>SQL</td>\n",
       "      <td>Hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Statistics</td>\n",
       "      <td>Education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-1</td>\n",
       "      <td>Not Identified</td>\n",
       "      <td>Not Idenified</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SkillID           Skill       Category\n",
       "0        1          Python           Hard\n",
       "1        2             SQL           Hard\n",
       "2        3         BigData           Hard\n",
       "3        4           NumPy           Hard\n",
       "4        5          Spring           Hard\n",
       "5        6      Mathematcs      Education\n",
       "6        7             SQL           Hard\n",
       "7        8      Statistics      Education\n",
       "8       -1  Not Identified  Not Idenified"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skill_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Skill_ID'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-106-5e63a9650f3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_tmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskill_source\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Skill_ID'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Skill_ID'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m   6377\u001b[0m                      \u001b[0mright_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mright_on\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mleft_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6378\u001b[0m                      \u001b[0mright_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mright_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6379\u001b[0;31m                      copy=copy, indicator=indicator, validate=validate)\n\u001b[0m\u001b[1;32m   6380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6381\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecimals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     58\u001b[0m                          \u001b[0mright_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mright_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                          \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindicator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m                          validate=validate)\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    548\u001b[0m         (self.left_join_keys,\n\u001b[1;32m    549\u001b[0m          \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m          self.join_names) = self._get_merge_keys()\n\u001b[0m\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_get_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    854\u001b[0m                             right_keys.append(\n\u001b[1;32m    855\u001b[0m                                 right._get_label_or_level_values(\n\u001b[0;32m--> 856\u001b[0;31m                                     rk, stacklevel=stacklevel))\n\u001b[0m\u001b[1;32m    857\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                             \u001b[0;31m# work-around for merge_asof(right_index=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[0;34m(self, key, axis, stacklevel)\u001b[0m\n\u001b[1;32m   1377\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1378\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1379\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1381\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Skill_ID'"
     ]
    }
   ],
   "source": [
    "df_jobs = df_tmp.merge(skill_source, left_on='Skill_ID', right_on='Skill_ID', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_jobs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-104-804b07dd529a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_jobs' is not defined"
     ]
    }
   ],
   "source": [
    "df_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_jobs = df_jobs.drop_duplicates(subset={'Job_ID','Skill_ID'}, keep='first', inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_jobs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
